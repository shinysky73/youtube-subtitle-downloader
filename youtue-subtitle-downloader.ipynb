{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPGHlUGbYJbPmjTQHr14LIr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# 예시 URL : https://www.youtube.com/watch?v=jC4v5AS4RIM"],"metadata":{"id":"rH9iJu0yDYyO","executionInfo":{"status":"ok","timestamp":1699519957575,"user_tz":-540,"elapsed":308,"user":{"displayName":"신희천(브렛)","userId":"00376704539921533559"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["## 사용방법\n","아래의 입력 및 선택사항을 선택 후 상단메뉴의 Runtime > Run all 를 실행해주세요\n","\n","GPU 서버를 선택하면 음성 추출을 더 빠르게 수행할수 있습니다"],"metadata":{"id":"A8vIawS-H-co"}},{"cell_type":"code","source":["#@title 유튜브 URL 입력(필수 입력사항)\n","youtube_url = \"\" #@param {type:\"string\"}"],"metadata":{"id":"5jJbV4he7hs-","cellView":"form","executionInfo":{"status":"ok","timestamp":1699519958024,"user_tz":-540,"elapsed":3,"user":{"displayName":"신희천(브렛)","userId":"00376704539921533559"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#@title 유튜브 영상의 언어를 선택하세요.\n","language = \"English\" # @param [\"English\", \"Korean\"]"],"metadata":{"cellView":"form","id":"c7ryuWz9C6Sk","executionInfo":{"status":"ok","timestamp":1699519958024,"user_tz":-540,"elapsed":2,"user":{"displayName":"신희천(브렛)","userId":"00376704539921533559"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#@title (선택) 영상 추출 모델의 크기를 선택하세요. large 로 갈수록 성능은 좋아지지만 오래 걸림\n","model_size = \"base\" # @param [\"base\",\"small\",\"medium\",\"large\"]"],"metadata":{"cellView":"form","id":"cYkIVTdIIlWd","executionInfo":{"status":"ok","timestamp":1699519958024,"user_tz":-540,"elapsed":2,"user":{"displayName":"신희천(브렛)","userId":"00376704539921533559"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#@title (선택) 영어 유튜브 영상일 경우 한글 자막 생성 여부를 선택하세요.\n","is_translate = \"Yes\"  # @param [\"Yes\", \"No\"]"],"metadata":{"cellView":"form","id":"R41Yizm1F_Nk","executionInfo":{"status":"ok","timestamp":1699519958024,"user_tz":-540,"elapsed":2,"user":{"displayName":"신희천(브렛)","userId":"00376704539921533559"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#@title (선택) 영상과 자막을 합칠지 여부를 선택하세요 (자막을 입히는 경우 시간이 오래걸림)\n","is_merge = \"Yes\"  # @param [\"Yes\", \"No\"]"],"metadata":{"cellView":"form","id":"-kdbF_g0EBoc","executionInfo":{"status":"ok","timestamp":1699519958025,"user_tz":-540,"elapsed":3,"user":{"displayName":"신희천(브렛)","userId":"00376704539921533559"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#@title (옵션) 영상과 자막을 합칠 경우 자막의 언어를 선택하세요.\n","merge_language = \"Korean\" # @param [\"English\", \"Korean\"]"],"metadata":{"cellView":"form","id":"j2B9u0_jEXyH","executionInfo":{"status":"ok","timestamp":1699519958025,"user_tz":-540,"elapsed":3,"user":{"displayName":"신희천(브렛)","userId":"00376704539921533559"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## 패키지 설치 (설치시간 몇분 걸림)"],"metadata":{"id":"E5Q8SQrz9A9E"}},{"cell_type":"code","execution_count":8,"metadata":{"cellView":"form","id":"ry_M_ngDvf0P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699520170353,"user_tz":-540,"elapsed":212331,"user":{"displayName":"신희천(브렛)","userId":"00376704539921533559"}},"outputId":"86cea3b4-72c5-42b2-dd4b-95d815cd71e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following NEW packages will be installed:\n","  fonts-nanum\n","0 upgraded, 1 newly installed, 0 to remove and 19 not upgraded.\n","Need to get 10.3 MB of archives.\n","After this operation, 34.1 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum all 20200506-1 [10.3 MB]\n","Fetched 10.3 MB in 1s (12.1 MB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package fonts-nanum.\n","(Reading database ... 120874 files and directories currently installed.)\n","Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n","Unpacking fonts-nanum (20200506-1) ...\n","Setting up fonts-nanum (20200506-1) ...\n","Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n","Collecting openai-whisper\n","  Downloading openai-whisper-20231106.tar.gz (798 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting triton==2.0.0 (from openai-whisper)\n","  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.58.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.23.5)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.1.0+cu118)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.1)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.1.0)\n","Collecting tiktoken (from openai-whisper)\n","  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.27.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.13.1)\n","Collecting lit (from triton==2.0.0->openai-whisper)\n","  Downloading lit-17.0.4.tar.gz (153 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.1/153.1 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.41.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2023.6.3)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.31.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2023.6.0)\n","INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n","Collecting torch (from openai-whisper)\n","  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch->openai-whisper)\n","  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch (from openai-whisper)\n","  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch->openai-whisper)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch->openai-whisper)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch->openai-whisper)\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m120.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch->openai-whisper)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch->openai-whisper)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch->openai-whisper)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch->openai-whisper)\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch->openai-whisper)\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch->openai-whisper)\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch->openai-whisper)\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch->openai-whisper)\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper) (67.7.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper) (0.41.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n","Building wheels for collected packages: openai-whisper, lit\n","  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-whisper: filename=openai_whisper-20231106-py3-none-any.whl size=801353 sha256=53f95b1b2ed5aa5181440042539c54570fe544e896c0b203fd43cb0b75071697\n","  Stored in directory: /root/.cache/pip/wheels/e6/f6/72/ce51aa2af2b82a54decb6e20e211de3e4787f8a44898a81340\n","  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lit: filename=lit-17.0.4-py3-none-any.whl size=93257 sha256=e09da814a0287bba4052b1b81bd8c216705f6fbf6d713536ec0542469860eee9\n","  Stored in directory: /root/.cache/pip/wheels/be/ae/00/696c57d438bfc7c0e89c4c379083ea08b1c2e54d85a5f7cd7c\n","Successfully built openai-whisper lit\n","Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, tiktoken, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, openai-whisper\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.1.0\n","    Uninstalling triton-2.1.0:\n","      Successfully uninstalled triton-2.1.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.1.0+cu118\n","    Uninstalling torch-2.1.0+cu118:\n","      Successfully uninstalled torch-2.1.0+cu118\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires openai, which is not installed.\n","torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n","torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n","torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n","torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed lit-17.0.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 openai-whisper-20231106 tiktoken-0.5.1 torch-2.0.1 triton-2.0.0\n","Collecting pytube\n","  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting googletrans==4.0.0rc1\n","  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting ffmpeg-python\n","  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n","Collecting httpx==0.13.3 (from googletrans==4.0.0rc1)\n","  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (2023.7.22)\n","Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0rc1)\n","  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (1.3.0)\n","Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0rc1)\n","  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0rc1)\n","  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0rc1)\n","  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n","Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0rc1)\n","  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1)\n","  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1)\n","  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1)\n","  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n","Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1)\n","  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n","Building wheels for collected packages: googletrans\n","  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17396 sha256=040092f4dc3df936e66dd2f37c0de5deba7ceb5c46ae115af26273a6e3354ed3\n","  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n","Successfully built googletrans\n","Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, pytube, idna, hstspreload, h2, ffmpeg-python, httpcore, httpx, googletrans\n","  Attempting uninstall: chardet\n","    Found existing installation: chardet 5.2.0\n","    Uninstalling chardet-5.2.0:\n","      Successfully uninstalled chardet-5.2.0\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.4\n","    Uninstalling idna-3.4:\n","      Successfully uninstalled idna-3.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n","torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n","torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed chardet-3.0.4 ffmpeg-python-0.2.0 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2023.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 pytube-15.0.0 rfc3986-1.5.0\n"]}],"source":["# @title\n","#pip install git+https://github.com/openai/whisper.git -q\n","! sudo apt-get install -y fonts-nanum\n","! pip install -U openai-whisper\n","! pip install pytube googletrans==4.0.0rc1 ffmpeg-python"]},{"cell_type":"markdown","source":["## 클래스 모음"],"metadata":{"id":"dO94FsoW9SXx"}},{"cell_type":"code","source":["# @title\n","from IPython.display import display\n","from pytube import YouTube\n","import math\n","import whisper\n","import pandas as pd\n","import requests\n","from pathlib import Path\n","\n","from google.colab import files\n","\n","from googletrans import Translator\n","import re\n","import threading\n","\n","class YoutubeDownloader:\n","\n","    def __init__(self, url):\n","        self.title = None\n","        self.filename = None\n","        self.audio_name = None\n","        self.vide_name = None\n","        self.youtube_video = YouTube(url)\n","\n","    def make_safe_filename(self, s: str) -> str:\n","      def safe_char(c):\n","          if c.isalnum():\n","              return c\n","          else:\n","              return \"_\"\n","      return \"\".join(safe_char(c) for c in s).strip(\"_\").replace(\"__\", \"_\").replace(\"__\", \"_\")\n","\n","    def download(self):\n","        self.title = self.youtube_video.title\n","        self.filename = self.make_safe_filename(self.title)\n","\n","        video = self.youtube_video.streams.filter(progressive=\"True\", file_extension=\"mp4\").order_by('resolution').desc()[0]\n","        audio = self.youtube_video.streams.get_audio_only()\n","\n","        self.video_name = f\"{self.filename}.mp4\"\n","        video.download(filename=self.video_name)\n","\n","        self.audio_name = f\"{self.filename}.mp3\"\n","        audio.download(filename=self.audio_name)\n","\n","class Transcriber:\n","\n","    def __init__(self, model, downloader: YoutubeDownloader, language: str = \"en\"):\n","        self.model = model\n","        self.audio_name = downloader.audio_name\n","        self.language = language\n","\n","    def transcribe(self):\n","        self.transcribed_result = self.model.transcribe(self.audio_name, word_timestamps=False, language=self.language)\n","\n","class SubtileMaker:\n","\n","    def __init__(self, script, downloader: YoutubeDownloader, language: str = \"en\"):\n","        self.script = script\n","        self.filename = downloader.filename\n","        self.language = language\n","\n","    def reformat_time(self, second):\n","        m, s = divmod(second, 60)\n","        h, m = divmod(m, 60)\n","        hms = \"%02d:%02d:%s\" % (h, m, str('%.3f' % s).zfill(6))\n","        hms = hms.replace('.', ',')\n","        return hms\n","\n","    def execute(self):\n","        seg = self.script['segments']\n","        srt_path = f\"{self.filename}_{self.language}.srt\"\n","        with open(srt_path, 'w', encoding='utf-8') as f:\n","            write_content = [str(n + 1) + '\\n'\n","                            + self.reformat_time(i['start'])\n","                            + ' --> '\n","                            + self.reformat_time(i['end']) + '\\n'\n","                            + i['text'] + '\\n\\n'\n","                            for n, i in enumerate(seg)]\n","            f.writelines(write_content)\n","\n","\n","class SubtitleTranslator:\n","\n","  def __init__(self, downloader: YoutubeDownloader, from_language: str = \"en\", to_language: str = \"ko\"):\n","      self.filename = downloader.filename\n","      self.from_language = from_language\n","      self.to_language = to_language\n","\n","  def __translate(self, translator, text, n):\n","\n","      if text == \"\" or text == '\\n':\n","          return text\n","\n","      text = text.rstrip('\\n')\n","      if re.match(r\"^[0-9]+$\", text):\n","          return self.add_newline_if_missing(text)\n","\n","      if re.match(r\"\\d{2}:\\d{2}:\\d{2},\\d{3}\\s-->\\s\\d{2}:\\d{2}:\\d{2},\\d{3}\", text):\n","          return self.add_newline_if_missing(text)\n","\n","      return self.add_newline_if_missing(translator.translate(text=text, dest=self.to_language).text)\n","\n","  def add_newline_if_missing(self, s):\n","      s = str(s)\n","      if not s.endswith('\\n'):\n","          s += '\\n'\n","      return s\n","\n","  def translate_task(self, lines, translator_fun, result_map, i, translator):\n","      print(\"thread id: \", i, \"lines num: \", len(lines))\n","      result_map[i] = [translator_fun(translator, line, n) for n, line in enumerate(lines)]\n","\n","  def translate_file(self, translator_fun, file1, file2, thread_nums, translator=None):\n","      with open(file1, 'r', encoding='utf-8') as f1, open(file2, 'w', encoding='utf-8') as f2:\n","          lines = f1.readlines()\n","          print(\"translate file total lines: \", len(lines))\n","          result = self.get_translate_result(lines, thread_nums, translator, translator_fun)\n","          f2.writelines(result)\n","          print(\"\\ntranslate write file done\")\n","\n","  def get_translate_result(self, lines, thread_nums, translator, translator_fun):\n","      result_map = self.get_translate_threads_result(lines, thread_nums, translator, translator_fun)\n","      result = []\n","      for key in sorted(result_map):\n","          result.extend(result_map.get(key))\n","      return result\n","\n","  def get_translate_threads_result(self, lines, thread_nums, translator, translator_fun):\n","      result_map = {}\n","      threads = []\n","      n = len(lines) // thread_nums\n","      for i in range(1, thread_nums + 1):\n","          threads.append(\n","              threading.Thread(\n","                  target=self.translate_task,\n","                  args=(self.get_split_lines(i, lines, n, thread_nums), translator_fun, result_map, i, translator)\n","              )\n","          )\n","      for thread in threads:\n","          thread.start()\n","      for thread in threads:\n","          thread.join()\n","      return result_map\n","\n","  def get_split_lines(self, i, lines, n, thread_nums):\n","      if n * i <= len(lines):\n","          split_line = lines[(i - 1) * n:i * n]\n","      else:\n","          split_line = lines[(i - 1) * n:]\n","      if i == thread_nums and n * i < len(lines):\n","          split_line = lines[(i - 1) * n:]\n","      return split_line\n","\n","  def translate(self,thread_nums=2):\n","      #translator = Translator(from_lang=form, to_lang=to)\n","      translator = Translator()\n","      en_srt = f\"{self.filename}_en.srt\"\n","      ko_srt = f\"{self.filename}_ko.srt\"\n","      self.translate_file(self.__translate, en_srt, ko_srt, thread_nums, translator)\n"],"metadata":{"cellView":"form","id":"Hk7ZhnfBv0Lu","executionInfo":{"status":"ok","timestamp":1699520174391,"user_tz":-540,"elapsed":4043,"user":{"displayName":"신희천(브렛)","userId":"00376704539921533559"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## 모델 로드"],"metadata":{"id":"dmvUF_KhJ4_-"}},{"cell_type":"code","source":["# @title\n","print(\"모델 로딩중...\")\n","model = whisper.load_model(model_size)"],"metadata":{"cellView":"form","id":"RT6Qyip1Ic0L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699520178886,"user_tz":-540,"elapsed":4501,"user":{"displayName":"신희천(브렛)","userId":"00376704539921533559"}},"outputId":"84985329-a39f-4d7d-9aae-3cc29afe6c2d"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["모델 로딩중...\n"]},{"output_type":"stream","name":"stderr","text":["100%|████████████████████████████████████████| 139M/139M [00:01<00:00, 113MiB/s]\n"]}]},{"cell_type":"markdown","source":["## 실행코드"],"metadata":{"id":"QJ1_nhWrJ7wb"}},{"cell_type":"code","source":["# @title\n","from torch import e\n","import ffmpeg\n","import os\n","\n","\n","if language == \"English\":\n","  from_language = \"en\"\n","else:\n","  from_language = \"ko\"\n","\n","if merge_language == \"English\":\n","  merge_language = \"en\"\n","else:\n","  merge_language = \"ko\"\n","\n","if youtube_url:\n","\n","  print(\"유튜브 영상 다운로드 진행중 ...\")\n","  downloader = YoutubeDownloader(youtube_url)\n","  downloader.download()\n","\n","  print(\"음성 추출 진행중 ...\")\n","  transcriber = Transcriber(model=model, downloader=downloader, language=from_language)\n","  transcriber.transcribe()\n","\n","  print(\"자막 생성 진행중 ...\")\n","  srtmaker = SubtileMaker(transcriber.transcribed_result, downloader=downloader, language=from_language)\n","  srtmaker.execute()\n","\n","  if is_translate == \"Yes\":\n","    print(\"번역 진행중 ...\")\n","    translator = SubtitleTranslator(downloader)\n","    translator.translate(2)\n","\n","  if is_merge == \"Yes\":\n","    print(\"영상에 자막 추가 하는중 ...\")\n","    video = ffmpeg.input(downloader.video_name)\n","    audio = video.audio\n","    subtitle_video_path = f\"{downloader.filename}_subtitle.mp4\"\n","    subtitle_path = f\"{downloader.filename}_{merge_language}.srt\"\n","    ffmpeg.concat(\n","      video.filter('subtitles', subtitle_path, force_style=\"OutlineColour=&H40000000,BorderStyle=3\"),\n","      audio,\n","      v=1,\n","      a=1\n","    ).output(subtitle_video_path).run(quiet=True, overwrite_output=True)\n","\n","    print(\"영상 다운로드중 ...\")\n","    files.download(subtitle_video_path)\n","  else:\n","    subtitle_en_path = f\"{downloader.filename}_en.srt\"\n","    subtitle_ko_path = f\"{downloader.filename}_ko.srt\"\n","    files.download(downloader.video_name)\n","    if os.path.isfile(subtitle_en_path):\n","      files.download(subtitle_en_path)\n","    if os.path.isfile(subtitle_ko_path):\n","      files.download(subtitle_ko_path)\n","else:\n","  print(\"유튜브 URL을 입력하세요.\")\n"],"metadata":{"cellView":"form","id":"afMWwCNq4GZj","colab":{"base_uri":"https://localhost:8080/","height":225},"executionInfo":{"status":"ok","timestamp":1699520551002,"user_tz":-540,"elapsed":372121,"user":{"displayName":"신희천(브렛)","userId":"00376704539921533559"}},"outputId":"4a0b0619-6aee-4ac4-9ec2-982d8be50a66"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["유튜브 영상 다운로드 진행중 ...\n","음성 추출 진행중 ...\n","자막 생성 진행중 ...\n","번역 진행중 ...\n","translate file total lines:  612\n","thread id:  1 lines num:  306\n","thread id:  2 lines num:  306\n","\n","translate write file done\n","영상에 자막 추가 하는중 ...\n","영상 다운로드중 ...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_e4c0e27e-1069-4803-9f58-7f7074dbd576\", \"Master_the_Perfect_ChatGPT_Prompt_Formula_in_just_8_minutes_subtitle.mp4\", 41947953)"]},"metadata":{}}]}]}
